{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch, cost is 1.3453042697920807\n",
      "1 epoch, cost is 1.3390422067809316\n",
      "2 epoch, cost is 1.3330951112490328\n",
      "3 epoch, cost is 1.3274056571474622\n",
      "4 epoch, cost is 1.3219416925230454\n",
      "5 epoch, cost is 1.316707771871996\n",
      "6 epoch, cost is 1.311754388125618\n",
      "7 epoch, cost is 1.3071727048184474\n",
      "8 epoch, cost is 1.3030592612261622\n",
      "9 epoch, cost is 1.2994541331490246\n",
      "10 epoch, cost is 1.2962990137711112\n",
      "11 epoch, cost is 1.2934660154253672\n",
      "12 epoch, cost is 1.2908298355165362\n",
      "13 epoch, cost is 1.288309073889698\n",
      "14 epoch, cost is 1.2858610760567741\n",
      "15 epoch, cost is 1.283463329714454\n",
      "16 epoch, cost is 1.281101514574881\n",
      "17 epoch, cost is 1.278764626810349\n",
      "18 epoch, cost is 1.2764433660622108\n",
      "19 epoch, cost is 1.2741296097413586\n",
      "20 epoch, cost is 1.2718161965706702\n",
      "21 epoch, cost is 1.2694967960032097\n",
      "22 epoch, cost is 1.267165806586744\n",
      "23 epoch, cost is 1.2648182693042176\n",
      "24 epoch, cost is 1.2624497920063846\n",
      "25 epoch, cost is 1.2600564832961283\n",
      "26 epoch, cost is 1.2576348947432976\n",
      "27 epoch, cost is 1.2551819704751281\n",
      "28 epoch, cost is 1.2526950032846043\n",
      "29 epoch, cost is 1.250171596481443\n",
      "30 epoch, cost is 1.2476096307865587\n",
      "31 epoch, cost is 1.2450072356418518\n",
      "32 epoch, cost is 1.2423627643728448\n",
      "33 epoch, cost is 1.2396747727020117\n",
      "34 epoch, cost is 1.2369420001656997\n",
      "35 epoch, cost is 1.234163354037542\n",
      "36 epoch, cost is 1.2313378954064869\n",
      "37 epoch, cost is 1.2284648270983742\n",
      "38 epoch, cost is 1.2255434831667105\n",
      "39 epoch, cost is 1.222573319711299\n",
      "40 epoch, cost is 1.2195539068130137\n",
      "41 epoch, cost is 1.2164849213996134\n",
      "42 epoch, cost is 1.2133661408813237\n",
      "43 epoch, cost is 1.2101974374163504\n",
      "44 epoch, cost is 1.2069787726856638\n",
      "45 epoch, cost is 1.203710193073623\n",
      "46 epoch, cost is 1.2003918251664327\n",
      "47 epoch, cost is 1.1970238714942574\n",
      "48 epoch, cost is 1.1936066064551514\n",
      "49 epoch, cost is 1.1901403723699953\n",
      "50 epoch, cost is 1.1866255756274007\n",
      "51 epoch, cost is 1.183062682886209\n",
      "52 epoch, cost is 1.1794522173108066\n",
      "53 epoch, cost is 1.1757947548211052\n",
      "54 epoch, cost is 1.1720909203447467\n",
      "55 epoch, cost is 1.168341384063949\n",
      "56 epoch, cost is 1.1645468576534506\n",
      "57 epoch, cost is 1.1607080905093312\n",
      "58 epoch, cost is 1.1568258659710489\n",
      "59 epoch, cost is 1.1529009975409923\n",
      "60 epoch, cost is 1.14893432510714\n",
      "61 epoch, cost is 1.1449267111751613\n",
      "62 epoch, cost is 1.1408790371164852\n",
      "63 epoch, cost is 1.1367921994385661\n",
      "64 epoch, cost is 1.1326671060827855\n",
      "65 epoch, cost is 1.1285046727542325\n",
      "66 epoch, cost is 1.1243058192859519\n",
      "67 epoch, cost is 1.1200714660382438\n",
      "68 epoch, cost is 1.1158025303311483\n",
      "69 epoch, cost is 1.1114999229054525\n",
      "70 epoch, cost is 1.1071645444043277\n",
      "71 epoch, cost is 1.1027972818640621\n",
      "72 epoch, cost is 1.0983990051982135\n",
      "73 epoch, cost is 1.0939705636548598\n",
      "74 epoch, cost is 1.0895127822213215\n",
      "75 epoch, cost is 1.085026457944717\n",
      "76 epoch, cost is 1.0805123561297658\n",
      "77 epoch, cost is 1.0759712063672757\n",
      "78 epoch, cost is 1.0714036983373627\n",
      "79 epoch, cost is 1.0668104773204838\n",
      "80 epoch, cost is 1.0621921393362548\n",
      "81 epoch, cost is 1.0575492258144081\n",
      "82 epoch, cost is 1.0528822176833335\n",
      "83 epoch, cost is 1.0481915287386934\n",
      "84 epoch, cost is 1.043477498126469\n",
      "85 epoch, cost is 1.038740381740133\n",
      "86 epoch, cost is 1.033980342288607\n",
      "87 epoch, cost is 1.0291974377379627\n",
      "88 epoch, cost is 1.0243916077623691\n",
      "89 epoch, cost is 1.0195626577545953\n",
      "90 epoch, cost is 1.0147102398381718\n",
      "91 epoch, cost is 1.0098338301851224\n",
      "92 epoch, cost is 1.0049327017657912\n",
      "93 epoch, cost is 1.0000058914283962\n",
      "94 epoch, cost is 0.9950521599092687\n",
      "95 epoch, cost is 0.9900699429885071\n",
      "96 epoch, cost is 0.9850572915012558\n",
      "97 epoch, cost is 0.9800117972540722\n",
      "98 epoch, cost is 0.9749305010297336\n",
      "99 epoch, cost is 0.969809777730067\n",
      "[[-0.49398842  0.33756559 -0.34662663]\n",
      " [-1.05815749  0.90592826  0.87091999]\n",
      " [ 0.67006162 -0.35269279  1.43930245]\n",
      " [ 0.45584441 -0.04266014  0.89842977]] [[ 0.41854877 -0.09240652 -0.00178365]] [[ 1.11280408 -1.37618887]\n",
      " [-0.26990166  0.52186974]\n",
      " [-0.68294295  0.42148248]] [[ 0.14659089 -0.02535971]]\n",
      "(array([[0.47841062, 0.88962513, 0.99983944],\n",
      "       [0.41717445, 0.95883012, 0.99999994],\n",
      "       [0.2089713 , 0.99724883, 1.        ]]), array([[0.43930666, 0.55031417],\n",
      "       [0.41801961, 0.57990815],\n",
      "       [0.36055247, 0.65225651]]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parameter_initializer(n1, n2, n3):\n",
    "    \"\"\" 初始化权值 \"\"\"\n",
    "    w1 = np.random.normal(scale=(2.0/n1)**0.5, size=(n1, n2))\n",
    "    b1 = np.zeros(shape=(1,n2))\n",
    "    w2 = np.random.normal(scale=(2.0/n2)**0.5, size=(n2, n3))\n",
    "    b2 = np.zeros(shape=(1, n3))\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def sigmoid(z):\n",
    "    a = 1/(1+np.exp(-z))\n",
    "    return a\n",
    "\n",
    "def forward_propagate(x, w1, b1, w2, b2):\n",
    "    \"\"\" 构建三层神经网络 -- 前向传播 \"\"\"\n",
    "    \"\"\" x.shape = (m,n1)\n",
    "        y.shape = (m, n3)\n",
    "        w1.shape = (n, n2)\n",
    "        b1.shape = (1, n2)\n",
    "        w2.shape = (n2, n3)\n",
    "        b2.shape = (1, n3)\n",
    "    \"\"\"\n",
    "    z_1 = np.dot(x, w1) + b1\n",
    "    a_1 = sigmoid(z_1)\n",
    "    z_2 = np.dot(a_1, w2) + b2\n",
    "    output = sigmoid(z_2)\n",
    "    return a_1, output\n",
    "\n",
    "def loss(output, y):\n",
    "    \"\"\" 损失函数 \"\"\"\n",
    "    cross_entropy = -((1-y)*np.log(1-output) + y * np.log(output))\n",
    "    cost = np.mean(np.sum(cross_entropy, axis=1))\n",
    "    return cost\n",
    "\n",
    "def back_propagate(w1,b1, w2, b2, a_1, output, y, learning_rate):\n",
    "    \"\"\" 反向传播 \"\"\"\n",
    "    m = y.shape[0]\n",
    "    dz_2 = output - y    # (m, n3)\n",
    "    dw2 = 1/m * np.dot(a_1.T, dz_2)  # (n2, n3)\n",
    "    db2 = 1/m * np.sum(dz_2, axis=0, keepdims=True)\n",
    "\n",
    "    # 梯度下降\n",
    "    w2 = w2 - learning_rate * dw2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "\n",
    "    dz_1 = np.dot(dz_2, w2.T) * ((1-a_1)*a_1)  # sigmoid(z_1)的导数  # (m, n2)\n",
    "    dw1 = 1/m * np.dot(x.T, dz_1)  # (n1, n2)\n",
    "    db1 = 1/m * np.sum(dz_1, axis=0, keepdims=True)  # (1, n2)\n",
    "\n",
    "    w1 = w1 - learning_rate * dw1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def bpnn(x, y, epochs, learning_rate):\n",
    "    w1,b1,w2,b2 = parameter_initializer(4,3,2)\n",
    "    for epoch in range(epochs):\n",
    "        a_1, output = forward_propagate(x, w1, b1, w2, b2)\n",
    "        cost = loss(output, y)\n",
    "        print(\"{} epoch, cost is {}\".format(epoch, cost))\n",
    "        w1, b1, w2, b2 = back_propagate(w1, b1, w2, b2, a_1, output, y, learning_rate)\n",
    "    return w1,b1,w2,b2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    x = np.arange(0,20).reshape(5,4)\n",
    "    y = np.array([[1,0],[1,0],[0,1],[0,1],[0,1]], dtype=float).reshape(5,2)\n",
    "\n",
    "    w1, b1, w2, b2 = bpnn(x, y, 100, 0.1)\n",
    "    print(w1, b1, w2, b2)\n",
    "\n",
    "    # 测试效果\n",
    "    x_test = np.array([[1,3,2,4], [4,5,7,4], [7,9,12,7]])\n",
    "    output = forward_propagate(x_test, w1, b1, w2, b2)\n",
    "\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch19529: 0.015481569950039227\n",
      "\n",
      "\n",
      "Epoch39595: 0.01042822001077979\n",
      "\n",
      "\n",
      "Epoch59676: 0.008364547147068455\n",
      "\n",
      "\n",
      "Epoch81002: 0.009030854097557137\n",
      "\n",
      "\n",
      "Epoch102938: 0.006095252666154289\n",
      "\n",
      "\n",
      "Epoch124864: 0.005074369524129282\n",
      "\n",
      "\n",
      "Epoch146792: 0.004543823103674674\n",
      "\n",
      "\n",
      "Epoch168694: 0.004324672258388802\n",
      "\n",
      "\n",
      "Epoch190560: 0.004249159627839161\n",
      "\n",
      "\n",
      "准确率为： 0.9933333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "class Cyrus_BP(object):\n",
    "    \"\"\"\n",
    "    layer 为神经网络各层神经元的个数,包括输出层神经元个数,传参形式以列表传入；\n",
    "    activate:为各层的激活函数，传参形式为字符串或列表，\n",
    "             若传入一个字符串，则各层激活函数相同，\n",
    "             若传入一个列表，则列表元素代表各层激活函数\n",
    "             可传参数有：（1）sigmoid：S型函数\n",
    "                         （2）tanh：双曲正弦函数\n",
    "                         （3）relu:max(0,x)函数\n",
    "                         （4）purline：线性函数\n",
    "                         （5）softsign：平滑函数\n",
    "\n",
    "    lr:学习率，默认为0.01\n",
    "    epoch：最大迭代次数 默认为1e4\n",
    "    该模型具有的主要方法和属性如下：\n",
    "    fit(X,Y):模型拟合方法\n",
    "    predict(X):输出预测方法\n",
    "    predict_label(X):分类标签输出预测方法\n",
    "    activate:激活函数列表\n",
    "    W：权值列表\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,layer,**kargs):\n",
    "        self.layer = np.array(layer).reshape(1,-1)\n",
    "        if 'activate' in kargs.keys():\n",
    "            if str(type(kargs[\"activate\"])) == \"<class 'str'>\":    \n",
    "                self.activate = [kargs[\"activate\"]]*int(len(layer))\n",
    "            else:\n",
    "                self.activate = kargs[\"activate\"]\n",
    "        else:\n",
    "            self.activate = [\"sigmoid\"]*int(len(layer))\n",
    "        self.diff_activate = []\n",
    "        if 'lr' in kargs.keys():\n",
    "            self.lr = kargs[\"lr\"]\n",
    "        else:\n",
    "            self.lr = 0.01\n",
    "        if 'epoch' in kargs.keys():\n",
    "            self.epoch = kargs[\"epoch\"]\n",
    "        else:\n",
    "            self.epoch = int(1e4)\n",
    "            \n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.W = None\n",
    "        self.output = []\n",
    "        self.delta = []\n",
    "        self.sum_input = []\n",
    "    # 1、选择激活函数\n",
    "    def activation_func(self):\n",
    "        temp_func = []\n",
    "        for i in range(len(self.activate)):\n",
    "            if self.activate[i] == \"sigmoid\":\n",
    "                temp_func.append(lambda x:1/(1+np.exp(-x)))\n",
    "                self.diff_activate.append(lambda x:(1/(1+np.exp(-x)))*(1-(1/(1+np.exp(-x)))))\n",
    "            if self.activate[i] == \"tanh\":\n",
    "                temp_func.append(lambda x:(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x)))\n",
    "                self.diff_activate.append(lambda x:((-np.exp(x) + np.exp(-x))*(np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))**2 + 1))\n",
    "            if self.activate[i] == \"softsign\":\n",
    "                temp_func.append(lambda x:x/(1+np.abs(x)))\n",
    "                self.diff_activate.append(lambda x:1/((1+x/np.abs(x)*x)**2))\n",
    "            if self.activate[i] == \"relu\":\n",
    "                temp_func.append(lambda x:(x+np.abs(x))/(2*np.abs(x))*x)\n",
    "                self.diff_activate.append(lambda x:(x+np.abs(x))/(2*np.abs(x)))\n",
    "            if self.activate[i] == \"purline\":\n",
    "                temp_func.append(lambda x:x)\n",
    "                self.diff_activate.append(lambda x:1+x-x)\n",
    "        self.activate = temp_func\n",
    "    # 2、权值初始化函数\n",
    "    def init_w(self):\n",
    "        self.W = []\n",
    "        for i in range(self.layer.shape[1]):\n",
    "            if i == 0:\n",
    "                w = np.random.random([self.X.shape[1]+1,self.layer[0,i]])*2-1\n",
    "            else:\n",
    "                w = np.random.random([self.layer[0,i-1]+1,self.layer[0,i]])*2-1\n",
    "            self.W.append(w)\n",
    "     \n",
    "    # 3、权值调整函数\n",
    "    def update_w(self):\n",
    "        # 1 计算各层输出值\n",
    "        self.output = []\n",
    "        self.sum_input = []\n",
    "        for i in range(self.layer.shape[1]):\n",
    "            if i == 0:\n",
    "                temp = np.dot(np.hstack((np.ones((self.X.shape[0],1)),self.X)),self.W[i])\n",
    "                self.sum_input.append(temp)\n",
    "                self.output.append(self.activate[i](temp))\n",
    "            else:\n",
    "                temp = np.dot(np.hstack((np.ones((self.output[i-1].shape[0],1)),self.output[i-1])),self.W[i])\n",
    "                self.sum_input.append(temp)\n",
    "                self.output.append(self.activate[i](temp))\n",
    "        # 2 求每层的学习信号\n",
    "        self.delta = [0 for i in range(len(self.output))]\n",
    "        for i in range(len(self.output)):\n",
    "            if i == 0:\n",
    "                self.delta [-i-1] = ((self.Y-self.output[-i-1])*self.diff_activate[-i-1](self.sum_input[-i-1]))\n",
    "            else:\n",
    "                self.delta [-i-1] = ((self.delta[-i].dot(self.W[-i][1:,:].T))*self.diff_activate[-i-1](self.sum_input[-i-1]))\n",
    "        # 3 更新权值\n",
    "        for i in range(len(self.W)):\n",
    "            if i == 0 :\n",
    "                self.W[i] += self.lr * np.hstack((np.ones((self.X.shape[0],1)),self.X)).T.dot(self.delta[i])\n",
    "            else:\n",
    "                self.W[i] += self.lr * np.hstack((np.ones((self.output[i-1].shape[0],1)),self.output[i-1])).T.dot(self.delta[i])\n",
    "                            \n",
    "    def fit(self,X,Y):\n",
    "        self.X = np.array(X)\n",
    "        self.Y = np.array(Y)\n",
    "        # 1 权值初始化\n",
    "        self.init_w()\n",
    "\n",
    "        # 2 选择激活函数\n",
    "        self.activation_func()\n",
    "        # 3 更新权值\n",
    "        start_time = time.time()\n",
    "        for i in range(int(self.epoch)):\n",
    "            self.update_w()\n",
    "            end_time = time.time()\n",
    "            if end_time - start_time >= 5:\n",
    "                print(\"Epoch%d:\"%(i+1),np.mean(np.square(self.Y-self.output[-1])))\n",
    "                print(\"\\n\")\n",
    "                start_time = time.time()\n",
    "    def predict(self,x):\n",
    "        x = np.array(x)\n",
    "        result = []\n",
    "        for i in range(self.layer.shape[1]):\n",
    "            if i == 0:\n",
    "                result.append(self.activate[i](np.dot(np.hstack((np.ones((x.shape[0],1)),x)),self.W[i])))\n",
    "            else:\n",
    "                result.append(self.activate[i](np.dot(np.hstack((np.ones((result[i-1].shape[0],1)),result[i-1])),self.W[i])))\n",
    "        return result[-1]\n",
    "    def predict_label(self,x):\n",
    "        x = np.array(x)\n",
    "        result = []\n",
    "        for i in range(self.layer.shape[1]):\n",
    "            if i == 0:\n",
    "                result.append(self.activate[i](np.dot(np.hstack((np.ones((x.shape[0],1)),x)),self.W[i])))\n",
    "            else:\n",
    "                result.append(self.activate[i](np.dot(np.hstack((np.ones((result[i-1].shape[0],1)),result[i-1])),self.W[i])))\n",
    "        result = result[-1]   \n",
    "        return np.array([result[i].argmax() for i in range(result.shape[0])]).reshape(-1,1)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    bp = Cyrus_BP([50,10,3],lr=0.01,epoch = 2e5,activate = [\"softsign\",\"softsign\",\"softsign\"])\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    data = load_iris()\n",
    "    X = data[\"data\"]\n",
    "    Y = data[\"target\"]\n",
    "    import pandas as pd\n",
    "    # 用神经网络进行分类时，需把输出先进行独热编码\n",
    "    Y1 = pd.get_dummies(Y) # 进行独热编码或将期望输出转换为哑变量\n",
    "    bp.fit(X,Y1)\n",
    "    Y_pre = bp.predict_label(X)\n",
    "    print(\"准确率为：\",accuracy_score(Y,Y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
